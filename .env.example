# -----------------------------------------------------------------------------
# LightRAG Environment Variables
# Based on official env.example and your specific configuration
# -----------------------------------------------------------------------------

# --- Server Configuration ---
HOST=0.0.0.0
PORT=9621
WEBUI_TITLE='FOLIO Legal RAG'
WEBUI_DESCRIPTION="Graph Based RAG System for FOLIO Ontology"
OLLAMA_HOST=http://ollama:11434

# --- Text Processing & Summary ---
# MAX_TOKEN_ENTITY_DESC=4000 # Max tokens for entity description, if using entity extraction
SUMMARY_LANGUAGE=English # For summary generation, if used

# --- Chunking (Defaults are usually fine) ---
# CHUNK_SIZE=512
# CHUNK_OVERLAP_SIZE=100

# --- LLM Configuration ---
LLM_BINDING=ollama
LLM_MODEL=llama3.1:8b
LLM_BINDING_HOST=http://ollama:11434
MAX_TOKENS=8192


# --- Embedding Configuration ---
# To use HuggingFace models from config.ini, comment out these binding variables:
EMBEDDING_BINDING=ollama
EMBEDDING_BINDING_HOST=http://ollama:11434
EMBEDDING_MODEL=all-minilm
EMBEDDING_DIM=384


# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_HOST=localhost
NEO4J_PORT=7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=neo4j

# LightRAG Configuration
LIGHTRAG_API_URL=http://localhost:9621

#OPENAI
OPENAI_API_KEY='placeholder'